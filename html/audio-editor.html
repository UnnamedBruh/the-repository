<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audio Editor</title>
    <style>
        /* Basic styling for the UI */
        #controls {
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <input type="file" id="fileInput" />
    <div id="controls">
        <button id="normalizeBtn">Normalize</button>: Makes it so most of the sound is less loud when being played.
        <br>
        <button id="applyGainBtn">Apply Gain</button><input type="range" id="gainSlider" min="0" max="2" step="0.1" value="1" />: Makes the sound louder or softer (fully blue doubles the volume, fully gray mutes the volume)
        <br>
        <button id="applyReverbBtn">Apply Echo</button> how long echo lasts: <input type="number" id="echoInput" min="0" step="0.1" value="1" /> how loud echo is: <input type="number" id="likelinessInput" min="1" step="0.1" value="5" /><br>
        <button id="applyFilterBtn">Apply Filter</button><select id="filterTypeInput"><option>lowpass</option><option>highpass</option></select>filter frequency <input type="number" id="filterFrequencyInput" min="0" step="1" value="12000" max="24000">: Lowpass means only frequencies below the number specified (per Hurtz), while highpass means only frequencies above the number specified (per Hurtz).
        <br>
        <button id="playBtn">Play</button>
        <br>
        <button id="restoreBtn">Restore Original Sound</button>
        <br>
        <button id="downloadBtn">Download</button>
    </div>
    <script>
class AudioProcessor {
    constructor(audioData = new Float32Array([]), sampleRate = 48000) {
        this.audioData = audioData;
        this.sampleRate = sampleRate;
        this.backupData = audioData;
    }

    normalize() {
        if (this.audioData.length === 0) return;
        const max = Math.max(...this.audioData);
        const min = Math.min(...this.audioData);
        const range = max - min;
        if (range === 0) return; // No change needed
        for (let i = 0; i < this.audioData.length; i++) {
            this.audioData[i] = (this.audioData[i] - min) / range;
        }
    }

    applyGain(gain) {
        if (gain < 0) {
            console.warn("Gain should be a positive value.");
            return;
        }
        for (let i = 0; i < this.audioData.length; i++) {
            this.audioData[i] *= gain;
        }
    }

    load(array) {
        if (!(array instanceof Float32Array)) {
            console.error("Input must be a Float32Array.");
            return;
        }
        this.audioData = array;
    }

    applySimpleReverb(likelinessOfEcho, echo, trailEcho = false) {
        if (echo <= 0) {
            console.warn("Echo strength should be a positive value.");
            return;
        }

        const delayLineLength = Math.floor(this.sampleRate * 0.1); // 100ms delay
        const feedbackAmount = likelinessOfEcho / 10;
        const output = new Float32Array(this.audioData.length);
        const delayBuffer = new Float32Array(delayLineLength);
        let delayIndex = 0;

        for (let i = 0; i < this.audioData.length; i++) {
            const inputSample = this.audioData[i];
            const delayedSample = delayBuffer[delayIndex];
            const reverbSample = inputSample + delayedSample * feedbackAmount;
            output[i] = reverbSample;
            delayBuffer[delayIndex] = reverbSample;
            delayIndex = (delayIndex + 1) % delayLineLength;
        }

        if (trailEcho) {
            const trailLength = this.audioData.length;
            const fadeOutFactor = 0.5; // Adjust for desired fade out effect
            const trailOutput = new Float32Array(this.audioData.length + trailLength);
            trailOutput.set(output);
            for (let i = 0; i < trailLength; i++) {
                trailOutput[this.audioData.length + i] = output[i] * Math.pow(fadeOutFactor, i / 500);
            }
            this.audioData = trailOutput;
        } else {
            this.audioData = output;
        }
    }

    filter(type, cutoffFrequency) {
        if (!['lowpass', 'highpass'].includes(type)) {
            console.error("Filter type must be 'lowpass' or 'highpass'.");
            return;
        }
        if (cutoffFrequency <= 0 || cutoffFrequency >= this.sampleRate / 2) {
            console.error("Cutoff frequency must be between 0 and the Nyquist frequency.");
            return;
        }

        const omega = 2 * Math.PI * cutoffFrequency / this.sampleRate;
        const alpha = Math.sin(omega) / 2;
        const a0 = 1 + alpha;
        const a1 = type === 'lowpass' ? -2 * Math.cos(omega) : 2 * Math.cos(omega);
        const a2 = 1 - alpha;
        const b0 = type === 'lowpass' ? (1 - Math.cos(omega)) / 2 : (1 + Math.cos(omega)) / 2;
        const b1 = type === 'lowpass' ? 1 - Math.cos(omega) : -(1 + Math.cos(omega));
        const b2 = type === 'lowpass' ? (1 - Math.cos(omega)) / 2 : (1 + Math.cos(omega)) / 2;

        const output = new Float32Array(this.audioData.length);
        let x1 = 0, x2 = 0; // Previous input samples
        let y1 = 0, y2 = 0; // Previous output samples

        for (let i = 0; i < this.audioData.length; i++) {
            const x0 = this.audioData[i];
            const y0 = (b0 / a0) * x0 + (b1 / a0) * x1 + (b2 / a0) * x2 - (a1 / a0) * y1 - (a2 / a0) * y2;

            output[i] = y0;

            // Shift the samples for the next iteration
            x2 = x1;
            x1 = x0;
            y2 = y1;
            y1 = y0;
        }

        this.audioData = output;
    }

    convertToWav() {
        const numChannels = 1; // Mono audio
        const buffer = new ArrayBuffer(44 + this.audioData.length * 2);
        const view = new DataView(buffer);

        // RIFF chunk descriptor
        writeString(view, 0, 'RIFF');
        view.setUint32(4, 36 + this.audioData.length * 2, true);
        writeString(view, 8, 'WAVE');

        // fmt sub-chunk
        writeString(view, 12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, numChannels, true);
        view.setUint32(24, this.sampleRate, true);
        view.setUint32(28, this.sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, 16, true);

        // data sub-chunk
        writeString(view, 36, 'data');
        view.setUint32(40, this.audioData.length * 2, true);

        // Write audio data
        let offset = 44;
        for (let i = 0; i < this.audioData.length; i++) {
            view.setInt16(offset, Math.max(-32768, Math.min(32767, this.audioData[i] * 32767)), true);
            offset += 2;
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        return new Blob([view], { type: 'audio/wav' });
    }

    restore() {
        this.audioData = this.backupData;
    }
}
        const fileInput = document.getElementById('fileInput');
        const normalizeBtn = document.getElementById('normalizeBtn');
        const applyGainBtn = document.getElementById('applyGainBtn');
        const gainSlider = document.getElementById('gainSlider');
        const applyReverbBtn = document.getElementById('applyReverbBtn');
        const echoInput = document.getElementById('echoInput');
        const likelinessInput = document.getElementById('likelinessInput');
        const applyFilterBtn = document.getElementById('applyFilterBtn');
        const filterTypeInput = document.getElementById('filterTypeInput');
        const frequencyInput = document.getElementById('frequencyInput');
        const playBtn = document.getElementById('playBtn');
        const restoreBtn = document.getElementById('restoreBtn');
        const downloadBtn = document.getElementById('downloadBtn');

        let audioProcessor = null;
        let audioContext = null;
        let sourceNode = null;

        fileInput.addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (file) {
                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const arrayBuffer = await file.arrayBuffer();
                    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    const channelData = audioBuffer.getChannelData(0);
                    audioProcessor = new AudioProcessor(new Float32Array(channelData));
                    console.log('Audio loaded.');
                } catch (error) {
                    console.error('Error processing audio file:', error);
                }
            }
        });

        normalizeBtn.addEventListener('click', () => {
            if (audioProcessor) {
                audioProcessor.normalize();
                console.log('Normalization applied.');
            }
        });

        applyGainBtn.addEventListener('click', () => {
            if (audioProcessor) {
                const gain = parseFloat(gainSlider.value);
                audioProcessor.applyGain(gain);
                console.log(`Gain applied: ${gain}`);
            }
        });

        applyReverbBtn.addEventListener('click', () => {
            if (audioProcessor) {
                const echo = parseFloat(echoInput.value);
                const likelinessOfEcho = parseFloat(likelinessInput.value);
                audioProcessor.applySimpleReverb(likelinessOfEcho, echo, true);
                console.log(`Reverb applied: Echo=${echo}, Likeliness=${likelinessOfEcho}`);
            }
        });

        playBtn.addEventListener('click', () => {
            if (audioProcessor && audioContext) {
                if (sourceNode) sourceNode.disconnect();
                sourceNode = audioContext.createBufferSource();
                const audioBuffer = audioContext.createBuffer(1, audioProcessor.audioData.length, audioProcessor.sampleRate);
                audioBuffer.copyToChannel(audioProcessor.audioData, 0);
                sourceNode.buffer = audioBuffer;
                sourceNode.connect(audioContext.destination);
                sourceNode.start();
                console.log('Playback started.');
            }
        });

        applyFilterBtn.addEventListener('click', () => {
            if (audioProcessor) {
                const filter = filterTypeInput.value;
                const freq = parseFloat(frequencyInput.value);
                audioProcessor.filter(filter, freq);
                console.log(`Filter applied: filterType=${filter}, frequency=${freq}`);
            }
        });

        restoreBtn.addEventListener('click', () => {
            if (audioProcessor) {
                audioProcessor.restore();
                console.log("Audio restored");
            }
        });

        downloadBtn.addEventListener('click', () => {
            if (audioProcessor) {
                const wavBlob = audioProcessor.convertToWav();
                const url = URL.createObjectURL(wavBlob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'edited-audio.wav';
                a.click();
                URL.revokeObjectURL(url);
                console.log('Download started.');
            }
        });
    </script>
</body>
</html>
